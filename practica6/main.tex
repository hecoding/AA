\documentclass{article}
\usepackage[utf8]{inputenc}
\usepackage[spanish]{babel}
\usepackage{subcaption}
\usepackage{graphicx}
\usepackage{pgffor}
\graphicspath{ {images/} }

\usepackage{color}
\definecolor{mygreen}{rgb}{0,0.6,0}
\definecolor{amber}{rgb}{1.0, 0.49, 0.0}

\usepackage{listings}
\lstdefinestyle{code}{
language=Octave,
frame=single,
breakatwhitespace=true,
breaklines=true,
basicstyle=\small\ttfamily,
tabsize=4,
numbers=left,
numberstyle=\tiny,
columns=fullflexible,
backgroundcolor=\color{white},
commentstyle=\color{mygreen},  % comment style
keywordstyle=\color{blue},     % keyword style
stringstyle=\color{amber},     % string literal style
}
\lstdefinestyle{snippet}{
language=Octave,
breakatwhitespace=true,
breaklines=true,
basicstyle=\small\ttfamily,
}
\lstdefinestyle{output}{
frame=single,
breakatwhitespace=true,
breaklines=true,
basicstyle=\small\ttfamily,
}

\addtolength{\textwidth}{1cm}
\addtolength{\textheight}{0.75cm}
\setcounter{section}{-1}

\title{Práctica 6}
\author{Héctor Laria Mantecón y Samuel Lapuente Jiménez}
\date{17 de diciembre de 2015}

\begin{document}

\maketitle

\section{Introducción}

\section{Elección de los parámetros $C$ y $\sigma$}
En la (figura decimal normal) vemos las diferentes combinaciones de $C$s y $\sigma$s, junto al tiempo que ha llevado computa el entrenamiento del modelo con dichos parámetros (cuanto el color sea más caliente y el punto más pequeño, más tiempo).
Cambiamos los ejes $x$ e $y$ a escala logarítmica (figura log normal) ya que las entradas también obedecen esta distribución.
Como podemos ver en (figura desde arriba), hay un pico de tiempo de cómputo conforme nos acercamos a $C = 10$ y $\sigma = 0.1$ en el que sin embargo no nos da un buen óptimo (figura derecha) ni mucho menos.

(meter todas las figuras aquí)

\section{Detección de spam}
Vamos a hacer 3 subconjuntos dentro del total de los mails (sumando {\tt easy_ham}, {\tt hard_ham} y {\tt spam}). El de entrenamiento, que tendrá el 60\% de todos los mails, el de validación, que tendrá el 20\% y el de testing, que tendrá el 20\% restante. Gracias a esto podremos probar los modelos entrenados y los resultados que nos darán no estarán condicionados por haber sido entrenados con los mismo datos.
bla bla
\subsection{Kernel gaussiano}
El número de acierto más alto en el conjunto de datos de validación ha sido de $86.667\%$, con $C = 3$ y $\sigma = 10$.
En el conjunto de datos de test podemos ver que ha clasificado bien un $83.03\%$ de los emails que eran spam.

\subsection{Kernel lineal}
El número de acierto más alto en el conjunto de datos de validación ha sido de $95.303\%$, con $C = 0.3$.
En el conjunto de datos de test podemos ver que ha clasificado bien un $96.818\%$.

\section{Conclusión}
blabla
Cuando tenemos ejemplos con una gran cantidad de atributos, es mejor utilizar un kernel lineal en términos de rapidez de entrenamiento y de porcentaje acertado.


\end{document}